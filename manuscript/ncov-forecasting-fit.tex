\documentclass[11pt,oneside,letterpaper]{article}

% graphicx package, useful for including eps and pdf graphics
\usepackage{graphicx}
\DeclareGraphicsExtensions{.pdf,.png,.jpg}

% basic packages
\usepackage{color}
\usepackage{parskip}
\usepackage{float}

% text layout
\usepackage{geometry}
\geometry{textwidth=15cm} % 15.25cm for single-space, 16.25cm for double-space
\geometry{textheight=22cm} % 22cm for single-space, 22.5cm for double-space

% helps to keep figures from being orphaned on a page by themselves
\renewcommand{\topfraction}{0.85}
\renewcommand{\textfraction}{0.1}

% bold the 'Figure #' in the caption and separate it with a period
% Captions will be left justified
\usepackage[labelfont=bf,labelsep=period,font=small]{caption}

% review layout with double-spacing
%\usepackage{setspace}
%\doublespacing
%\captionsetup{labelfont=bf,labelsep=period,font=doublespacing}

% cite package, to clean up citations in the main text. Do not remove.
\usepackage{cite}
%\renewcommand\citeleft{(}
%\renewcommand\citeright{)}
%\renewcommand\citeform[1]{\textsl{#1}}

% Remove brackets from numbering in list of References
\renewcommand\refname{\large References}
\makeatletter
\renewcommand{\@biblabel}[1]{\quad#1.}
\makeatother

\usepackage{authblk}
\renewcommand\Authands{ \& }
\renewcommand\Authfont{\normalsize \bf}
\renewcommand\Affilfont{\small \normalfont}
\makeatletter
\renewcommand\AB@affilsepx{, \protect\Affilfont}
\makeatother

% notation
\usepackage{amsmath}
\usepackage{amssymb}

% Inline comments by initials
\def\jhc#1{\textcolor{red}{[#1]}}
\definecolor{purple}{rgb}{0.459,0.109,0.538}
\def\tbc#1{\textcolor{purple}{[#1]}}

%%% TITLE %%%
\title{\vspace{1.0cm} \Large \bf
Fitness models provide accurate short-term forecasts of SARS-CoV-2 variant frequency
}
%
\author[1,2,*]{Eslam Abousamra}
\author[1,3,*]{Marlin Figgins}
\author[1,2,4]{Trevor Bedford}

\affil[1]{Vaccine and Infectious Disease Division, Fred Hutchinson Cancer Center, Seattle, WA, USA}
\affil[2]{Department of Epidemiology, University of Washington, Seattle, WA, USA}
\affil[3]{Department of Applied Mathematics, University of Washington, Seattle, WA, USA}
\affil[4]{Howard Hughes Medical Institute, Seattle, WA, USA}
\affil[*]{These authors contributed equally to this work.}


\date{}

\begin{document}

\maketitle

%%% ABSTRACT %%%
\begin{abstract}

Genomic surveillance of pathogen evolution is essential for public health response, treatment strategies, and vaccine development.
In the context of SARS-COV-2, multiple models have been developed including Multinomial Logistic Regression (MLR), Fixed Growth Advantage (FGA), Growth Advantage Random Walk (GARW) and Piantham that use observed variant sequence counts through time to analyze variant dynamics.
These models provide estimates of variant fitness and can be used to forecast changes in variant frequency.
We introduce a framework for evaluating real-time forecasts of variant frequencies, and apply this framework to the evolution of SARS-CoV-2 during 2022 in which multiple new viral variants emerged and rapidly spread through the population.
We compare models across representative countries with different intensities of genomic surveillance.
Retrospective assessment of model accuracy highlights that most models of variant frequency perform well and are able to produce reasonable forecasts.
We find that the simple MLR model provides less than 1\% mean absolute error when forecasting 30 days out for countries with robust genomic surveillence.
We investigate impacts of sequence quantity and quality across countries on forecast accuracy and conduct systematically downsampling to identify that 1000 sequences per week is fully sufficient for accurate short-term forecasts.
We conclude that fitness models represent a useful prognostic tool for short-term evolutionary forecasting.

\end{abstract}

%%% INTRODUCTION %%%
\section*{Introduction}

% Paragraph giving overview of SARS-COV-2 genomic surveillance and spread of variant viruses
The emergence of acute respiratory virus SARS-CoV-2 (COVID-19) and its subsequent circulating variants has had far-reaching implications on global health and worldwide economies \cite{onyeaka2021covid19}.
Due to its rapid evolution, original SARS-CoV-2 strains has been replaced by derived, more selectively advantageous variant lineages \cite{campbell2021increased}.
This dynamic landscape has led to emergence of Omicron, a highly transmissible variant that rapidly became the dominant strain altering the spread of COVID-19 \cite{who2022omicron}.
It has become increasingly evident that monitoring the evolution and dissemination of these variants remains crucial with SARS-CoV-2 continuing to evolve beyond Omicron \cite{carabelli2023sarscov2}.
Forecasting variant dynamics allows us to make informed decisions about vaccines and to predict variant-driven epidemics.


% Paragraph giving overview of previous application of fitness models (flu and SARS-CoV-2)
Fitness models are a key resource for forecasting changes in variant frequency or strain frequency through time.
These models were first introduced for the study of seasonal influenza virus \cite{luksza2014predictive, morris2018predictive, huddleston2020integrating} and there have relied on correlates of viral fitness such as mutations to epitope sites on influenza's surface proteins.
In modeling emergence and spread of SARS-CoV-2 variant viruses, the use of Multinomial Logistic Regression (MLR) has become commonplace \cite{annavajhala2021emergence, faria2021genomics, obermeyer2022analysis}.
Here, MLR is analogous to a population genetics model of haploid population in which different variants have a fixed growth advantage and are undergoing Malthusian growth.
As such, it presents a natural model for describing evolution and spread of SARS-CoV-2 variants.
Additionally, models introduced by Figgins and Bedford \cite{figgins2022sars} and by Piantham et al \cite{piantham2021estimating} incorporate case counts and variant-specific Rt, but still can be used to project variant frequencies.

% Broad overview of approach
Here, we systematically assess the predictive accuracy of fitness models for nowcasts and short-term forecasts of SARS-CoV-2 variant frequencies.
We focus on variants dynamics during 2022 in which multiple sub-lineages of Omicron including BA.2, BA.5 and BQ.1 spread rapidly throughout the world.
We compare across several countries including Australia, Brazil, Japan, South Africa, the United Kingdom, and the United States to assess genomic surveillance systems with different levels of throughput and timeliness.
To assess the performance of these models, we used mean absolute error (MAE) as a metric to compare the predicted frequencies to retrospective truth.
This metric allowed us to evaluate the accuracy and reliability of the models and to identify those that were most effective in predicting SARS-CoV-2 circulating variants trends.
We also examined a variety of variables that contribute to errors in these models and explored the role of sequence availability on nowcast and forecast errors through downsampling sequencing efforts for a sample location.

%%% RESULTS %%%
\section*{Results}

\subsection*{Reconstructing real-time forecasts}

We focus on SARS-CoV-2 sequence data shared to the GISAID EpiCoV database \cite{shu2017gisaid}.
Each sequence is annotated with both a collection date (relevant for understanding dynamics) as well as a submission date.
Here we seek to reconstruct datasets that were actually available on particular dates, and so we use use submission date to filter to sequences that were available at a specific analysis date.
We additionally filter to sequences collected up to 90 days before the analysis date.
We categorize each sequence by Nextstrain clade (21K, 21L, etc\dots) as such clades are generally at a reasonable level of granularity for understanding adaptive dynamics \cite{bloom2023fitness}; there are 7 clades circulating during 2022 vs hundreds of Pango lineages.
Resulting datasets for representative countries Japan and the USA for analysis dates of Apr 1 2022, Jun 1 2022, Sep 1 2022 and Dec 1 2022 are shown in Figure \ref{fig:dynamic_forecast_env}A.
We see consequential backfill in which genome sequences are not immediately available and instead available after a delay due to the necessary bottlenecks of sample acquisition, testing, sequencing, assembly and data deposition.
Thus, even estimating variant frequencies on the analysis date as a nowcast requires extrapolating from past week's data.
Different countries with different genomic surveillance systems have different levels of throughput as well as different amounts of delay between sample collection and sequence submission \cite{brito2022global}.

%%% dynamic_forecast_env %%%
\begin{figure}[tb!]
	\centering
	\includegraphics[width=0.9\textwidth=0.01]{figures/Dynamic_est_env.png}
	\caption{
		\textbf{Reconstructing available datasets and corresponding predictions for Japan and USA.}
		(A) Variant sequence counts categorized by Nextstrain clade from Japan and United States at 3 different analysis dates.
		Notice varying sequence availability at different observation dates.
		(B) +30 day frequency forecasts for variants in bimonthly intervals using the GARW variant Rt model.
		Each forecast trajectory is shown as a different colored line.
		Retrospective smoothed frequency is shown as a thick black line.
	}
	\label{fig:dynamic_forecast_env}
\end{figure}

We employ a sliding window in which we conduct an analysis twice each month (on the 1st and the 15th) and estimate variant frequencies from -90 days to +30 days relative to each analysis date.
For this projection we use the variant Rt model \cite{figgins2022sars} parameterized as a Growth Advantage Random Walk (GARW) to estimate variant-specific Rt and and from this changes in variant frequency through time.
Figure \ref{fig:dynamic_forecast_env}B shows resulting trajectories as colored lines.
Sometimes we see initial over-shoot or under-shoot as variant growth and decline, but there is general consistency across trajectories.
Additionally, we retrospectively reconstructed the simple 7-day smoothed frequency for across variants and present these trajectories as solid black lines.
We treat this retrospective trajectory as `truth' and thus deviations from model projections and retrospective truth can be assessed to determine nowcast and short-term forecasting accuracy.
Consistent with less available data, we observe that the model predictions for Japan were more frequently misestimated compared to the United States with particularly large differences for clades 22B (lineage BA.5) and 22E (lineage BQ.1) (Fig.~\ref{fig:dynamic_forecast_env}B).

\subsection*{Model error comparison}

%%% model_comp_table %%%
\begin{table}[tb!]
	\centering
	\caption{
		\textbf{Mean absolute error}
		The model with lowest error for each country / forecasting lag is bolded.
		}
	\includegraphics[width=0.6\textwidth]{figures/model_comp_table.png}
	\label{table:model_comp_table}
\end{table}

%%% model_comp_fig %%%
\begin{figure}[tb!]
	\centering
	\includegraphics[width=0.9\textwidth]{figures/model_comp.png}
	\caption{\textbf{MAE estimates across models and countries.}
	(A) Error increases as forecast target moves from hindcasting at -30 days to nowcasting at 0 days to forecasting at +30 days.
	(B) Distribution of absolute error on a log scale across models and across forecasting lags.
	This shows that most predictions have little error, while a small subset of predictions have large error.
	}
	\label{fig:model_comp_fig}
\end{figure}

We utilize five models for predicting the frequencies of SARS-CoV-2 variants in six countries (Australia, Brazil, Japan, South Africa, the United Kingdom, and the United States).
The simplest of these models is Multinomial Logistic Regression (MLR) commonly used in SARS-CoV-2 analyses \cite{annavajhala2021emergence, faria2021genomics, obermeyer2022analysis}, which uses only clade-specific sequence counts and has a fixed growth advantage for each variant.
More complex models include the Fixed Growth Advantage (FGA) and Growth Advantage Random Walk (GARW) parameterizations of the variant Rt model introduced by Figgins and Bedford \cite{figgins2022sars}, which uses case counts in addition to clade-specific sequence counts.
The Piantham et al model \cite{piantham2021estimating} operates on a similar principle in estimating variant-specific Rt, but differs in model details.
We compare the these four models to a naive model to serve as a reference model for comparison.
\jhc{Need a definition of the naive model here esp. since it is a baseline model.}
\tbc{Echoing this, I don't know how the naive model is implemented. Methods say `implemented as a 7-day moving average on the retrospective raw frequencies', but I don't know how this works when samples don't exist. Do you just use the last day with data? This needs to be described here.}
The use of multiple models that range in complexity allows for a comprehensive evaluation of the performance and robustness of different forecasting methods.
We compare forecasting accuracy across different time lags from -30 days back from date of analysis to target hindcast date, to +0 days from date of analysis to target nowcast date, to +30 days forward from date of analysis to target forecast date.

We compared our predictions to retrospective truth via 7-day smoothed frequency and calcuated mean absolute error (MAE) to assess the relative performance of the models for the six countries (Table~\ref{table:model_comp_table}).
The model with the lowest mean MAE error for each country is highlighted.
As expected we observe decreasing performance across models as lags increase from -30 days, to 0 days to +30 days.
For example, error increases for the MLR model from 0.1\%--1\% MAE at -30 days to 0.3\%--1.4\% MAE at 0 days, and to 0.4\%--1.4\% MAE at +30 days.
All four forecasting models performed better than the naive model, with MLR and the variant Rt models FGA and GARW performing slightly better than the Panthiam variant Rt model, except for in Australia where MLR, FGA and GARW performed decreased error by 2.4\% MAE compared to Panthiam.
Similar results are apparent when examining MAE as a continuous progression from -30 days to +30 days (Fig.~\ref{fig:model_comp_fig}A).

Absolute error varies across predictions for individual analysis dates and variants.
Its distribution is heterogeneous with most predictions having very little error, while a subset of predictions have larger error (Fig.~\ref{fig:model_comp_fig}B)
Here we use a 5\% absolute error threshold to classify an acceptable prediction vs unacceptable prediction (shown as dashed line).
At +30 days forecast lag we find that the Panthiam model has X\%, the MLE model has X\%, the FGA model has X\% and the GARW model has X\% of forecasts with error above this threshold.
This supports previous observation of similar performance across MLR and the FGA and GARW parameterizations of the variant Rt model.

\paragraph{Comparison of Growth Advantages}\ We investigated the behavior of the growth advantage of different variants in the aforementioned countries of interest using the MLR model due to its simplicity and performance.
We standardized the varying growth advantage by estimating the median growth advantage values as of that date.
We observed when and which variants stabilized in each country (Figure~\ref{fig:ga_estimates}).
The majority of countries displayed stabilization with regard to the clades 22A, 22B, and 22C variants, with the exception of Japan.
This discrepancy may be attributed to Japan's limited availability of sequence data and submission delays.
%they mostly stabilized except Japan % and why (motivated us to next step of analysis)

\begin{figure}[H]
	\centering
    \includegraphics[width=1.1\textwidth]{figures/ga_estimates.png}
	\caption{\textbf{Growth advantage of variants over time}
	Figure 3 demonstrates the stabilization of growth advantage of different clades relative to BA.1 \jhc{This is the first time we see references to Pango lineages which are a third clade nomenclature and not defined elsewhere in the paper.}.
	(A) Differences among growth advantages among three clades in six different countries.
	Noticing how quickly variants dial \jhc{?} and stabilize between different countries \jhc{Fragmented sentence}.
    \jhc{Vertical grid lines don't represent multiples of months or 30 days. Also, Clade 22E in the UK goes off the chart around October.}
	(B) Observation of stabilization of growth advantages according to the percent of variant frequency at observation.
    \jhc{I don't see how panel B shows ``stabilization'' of GAs. Maybe using a shared scale on the y-axis across countries and adding a horizontal line at y=1 would help emphasize convergence to a specific value?}
	}
	\label{fig:ga_estimates}
\end{figure}

\paragraph{Correlates of nowcast error}
\jhc{This section uses present tense, while the prior sections use the past tense.}
We further explore the relationship between variables of interest and the median mean absolute error \jhc{from which model?} across all locations with estimated Spearman correlation.
Variables included are observation dates, median submission delay, fraction of sequences at observation, and sequences available at observation.
We expect that a positive correlation between median submission delay and median MAE such that countries with longer delay exhibit higher errors and a negative correlation between fraction of sequences and sequences available at observation and median MAE such that countries with more robust sequencing efforts show lower errors.
While inter-country variability and other unexplored variables may weaken the correlation, we aimed to uncover meaningful trends into these complex phenomena.
% TODO: Add a sentence summarizing results of the figure
\jhc{Add a sentence or two summarizing results of the figure.}
The results obtained align to initial expectations regarding the trends between the sequencing data and MAE providing insights about the role of sequence submission rate (Figure \ref{fig:vars_of_interest}).


\begin{figure}[H]
	\centering
    \includegraphics[width=1.1\textwidth]{figures/Var_of_interest.png}
	\caption{\textbf{Variables of interest in predicting forecasting error}
    (A) Forecast MAEs visualized by country. %TODO: Points are medians of ....
    \jhc{What does each point represent?}
    Median MAEs are visualized with observation date (B),
    \jhc{What are the dates on the x axis of panel B? Is ``01'' the day of the month? Why are these x-axis labels different than similar panels in Figures 1 and 3?)}
    median submission delay (C),
    fraction of sequences available at time of observation (D),
    and the total number of sequences available at observation (E).
    For (C-E), we estimate the Spearman correlation between variables of interest and median MAE.
	}
	\label{fig:vars_of_interest}
\end{figure}

\paragraph{Effects of changing sequencing intensity on nowcast error}%

\jhc{This section is also in the present tense. Also, the section heading says ``nowcast error'' but the contents below describe forecasting error.}
We expect that as sequencing intensity decreases, our accuracy in forecasting may vary as we have decreasing levels of resolution in current variant frequencies and estimated growth advantages.
In order to investigate what number of sequences need to collected weekly to keep forecast error within acceptable bounds, we subsample existing sequences from the United Kingdom.
For context, we also compute the weekly sequences collected for selected countries globally (Figure \ref{fig:downscaling}.A).
We select the United Kingdom due to its large counts of available sequences, relatively short submission delay, and low nowcast error (Figure \ref{fig:vars_of_interest}.A,C,E).
We simulate several downscaled data sets by subsampling the collected sequences in the United Kingdom with some \jhc{which?} threshold for number of sequences per week and then fit the MLR model to each of the resulting data sets to see how the forecast accuracy varies with sampling intensity.
From this analysis, we find that increasing the number of sequences per week generally decreases the average error, but there are diminishing returns (Figure \ref{fig:downscaling}).
Additionally, the effect appears to saturate at different values depending on the forecast length.
We find that for 14 and 30 day forecasts sampling at least 1000-2000 sequences per week is appropriate for minimizing forecast error (Figure \ref{fig:downscaling}).


\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\linewidth]{figures/downscaling_sequencing.png}
    \caption{\textbf{Sequencing intensity affects forecast error.}
    (A) Mean sequences collected per week for selected country. Error bars denote 95\% confidence intervals of the mean. Dashed lines correspond to sampling rates used in (B-E).
    (B, C) Average MAE as a function of sequences collected per week colored by forecast horizon for the United Kingdom and Denmark. Here, ``0 days'' refers to nowcast error and the dash line corresponds to 5\% frequency error.
    (D, E) Proportion of forecasts within 5\% of retrospective frequency as a function of sequences collected for week for the United Kingdom and Denmark.
  }%
    \label{fig:downscaling}
\end{figure}

%%% DISCUSSION %%%
\section*{Discussion}

% Interpretation of the results

%Main findings

%Introducing the discussion

By developing a framework for comparing models of SARS-CoV-2 variant frequency and their forecasts, we find that most models of variant frequency perform well and are able to produce reasonable \jhc{how reasonable?} forecasts.
However, we find that naive models such as a 7-day moving average may not perform well due to the live nature of sequencing efforts e.g. delays between collection and availability of new samples.
Overall, it appears that differences in model accuracy are partially attributable to differences in the surveillance and sequencing efforts.

Consistent with evidence from SARS-CoV-2 time series forecasting analysis \cite{cramer2022unitedforecastinghub}, we find an increase in model errors and their variance as estimates go farther in the future from the observation date.
These long-term forecasts also appear to have heavier tails which indicate increase in extreme values and may be attributable to model break down or the emergence of new variants.

% Through our present framework, we modeled SARS-CoV-2 variant frequencies which allowed us to estimate transmission differences between clades.
% From our initial examination of the data we find that sequencing data exhibit temporal and geographical variation such that data vary based on the date of observation.
% Furthermore, we find that the six countries examined show varying ranges of back-filling of data, submission delays, and missing data.
%
% %patterns of error observed from analysis
% Taking a closer look into the errors generated by our models, we find that there is a consistent patterns of errors (Mean Absolute Error) observed among the different models examined that lend themselves to different interpretation.

%Brazil and japan and south africa? breaking? we wanna see why they break??
%Something may be wrong with them > next analysis?


Our findings suggest that the variations in error patterns observed are likely attributable to the way in which the models handle data issues across different countries.
As such inferences from forecasting models with underlying poor sequencing efforts may not be reliable without a contextual understanding of these limitations.
Additionally, standard modeling practices often involve presenting moving averages of retrospective frequencies of variants as the ``truth''.
However, our analysis of the naive model reveals a substantial discrepancy between the averages of past frequencies and the retrospective truth for all countries, except for the US and UK, where a rigorous sequencing effort is in place.
Importantly, we find that the multinomial logistic regression model (MLR) provides an improvement in accuracy over the naive model for Australia, Brazil, Japan, and South Africa.

%Trevors point about naive model that last 30 days is not actually truth
%Japan: Cornelius > It could be that they have a lot of bunching/overdispersion due to the way labs upload, e.g. one day itâ€™s all North, other day all South etc.

From our analysis of transmission dynamics, we find that it takes a shorter amount of time for different variant clades to stabilize in countries with more robust sequencing efforts.
\jhc{The previous sentence seems to conflate demographics with sequencing capacity.}
Our analysis also suggests that the variability between different countries' growth advantage estimates for different clades may not necessarily be biological but due to data limitations that we show here.
\jhc{What results in the paper support the previous sentence? I don't see where you quantified each country's sequencing capacity and compared that directly to variation in GA.}
We find that at higher frequencies the growth advantage estimates for the clades begin to stabilize though the frequency at which this begins to occur appears to differ by country.
 % To understand why different countries dial in quicker,
%temporal resolution is also important here, why at lower freq US and UK are still doing good

% * these errors affect growth advantage estimates  (figure 3)
% * different variant dynamics happening in different countries which explain why some countries (SA)
% * point about frequency needed for good estimates
% * from investigating variables of interest (which quantify sequencing efforts) we saw that it plays a role in explaining the variation in error

\jhc{Why isn't the following hypothesis the first one to consider instead of sequencing capacity?}
Though our analyses highlight the role of sequencing effort and intensity in reducing forecast error, it is important to note that non-sequencing heterogeneity through the transmission process and pathogen evolution may also explain error.
This could explain why South Africa did not show stabilization in growth advantages due to potentially differing variant dynamics or differences in the sequences effort itself.

We find that there are diminishing returns to increasing sequencing efforts however maintaining consistent sequencing efforts for pathogen surveillance can be done with 1,000-2,000 sequences per week.
\jhc{I see what you're trying to say in the previous sentence, but you might try rephrasing. For example ``maintaining consistent sequencing efforts'' isn't the outcome you get by collecting 1000 sequences; instead you get consistent nowcasting and forecasting estimates.}
This level of sequencing enables robust short-term forecasts of pathogen frequency dynamics at the level of a country and highlights the feasibility of pathogen surveillance for evolutionary forecasting.
Though, we are able to see the overall utility of these methods for providing short-term forecasts, we additionally find that no matter how many sequences are obtained some forecast error is maintained with standard methods for frequency forecasts.


%%% METHODS %%%
\section*{Methods}

\paragraph{Preparing sequence counts and case counts}

\jhc{Methods appear in present tense, but past tense would be appropriate.}
We prepared sequence count datasets to replicate a live nowcasting environment using the Nextstrain-curated SARS-CoV-2 sequence metadata which is created using the GISAID database.
For a given observation date, we filtered to all sequences which were collected 90 days before the observation date.
To properly account for submission delays in this collection process, we additionally filtered to those sequences which were submitted before the observation day.
These sequences are then counted according to their Nextstrain clade to produce sequence counts for each clade each day over the period of interest.
These sequence counts are produced independently for 6 countries including Australia, Brazil, Japan, the United States, the United Kingdom, and South Africa.
We repeated this process for a series of observations days which are the 1st and 15th of each month starting with  Janurary 1st, 2022 and ending with December 15th, 2022 giving a total of 24 datasets for each country.
Since two models (FGA and GARW) also use case counts for their estimates, we additionally prepare data sets using case counts over the time periods of interest as available from Our World in Data.

\paragraph{Frequency dynamics and transmission advantages}%

We implemented and evaluated several models of variant frequencies.
Each of these methods estimate variant frequencies over time and as well as estimate the transmission advantage of given variant relative to a baseline variant $R_{t}^{v} / R_{t}^{u}$.

The 4 models of interest are: Multinomial Logistic Regression (MLR), Piantham model \cite{piantham2021estimating}, a fixed growth advantage model (FGA)  \cite{figgins2022sars}, and a growth advantage random walk model (GARW)  \cite{figgins2022sars}.
Details for each of these models can be found in the corresponding citations above.
\jhc{Missing citations for models. Generally, the methods need a bit more description of how the different models work including how they are the same and how they differ.}

We provide a brief mathematical overview of these methods below.

The models mentioned above estimate the frequency  $f_{v}(t)$ of variant $v$ at time $t$ using sequence counts and/or case counts of the form described in the previous section.
All models simultaneously estimate the variant transmission advantages $\Delta_{v} = \frac{R_{t}^{v}}{R_{t}^{\text{pivot}}}$ where $R_{t}^{v}$ is the effective reproduction number for variant $v$.
We can interpret these transmission advantages as the relative effective reproduction number of a variant relative to some reference variant.

The multinomial logistic regression model estimates a fixed growth advantage using logistic regression with a variant-specific intercept and time coefficient, so that the frequency of variant $v$ at time $t$ can be modeled as
\begin{align*}
    f_{v}(t) = \frac{\exp(\alpha_{v} + \delta_{v} t)}{\sum_{u} \exp(\alpha_{u} + \delta_{u} t)},
\end{align*}
where $\Delta_{v} = \exp(\delta_{v} \tau)$ for some fixed generation time $\tau$.
The Piantham model relies on an approximation to the renewal equation wherein new infections do not vary greatly over the generation time of the virus.
This model generalizes the MLR in that it accounts for non-fixed generation time though it assumes little overall case growth. \cite{piantham2021estimating}

The fixed growth advantage model uses a renewal equation model based on both case counts and sequence counts, but assumes that the growth advantage $\Delta_{v}$ is constant in time. \cite{figgins2022sars}
The growth advantage random walk model also uses a renewal equation model based on both case counts and sequences, but allows variant growth advantages to vary smoothly in time. \cite{figgins2022sars}

The models used all differ in the complexity of their assumptions in computing the variant growth advantage which may affect forecasting accuracy.
Growth advantages presented in this manuscript are estimated relative to the baseline Omicron 21L (BA.1) strain, providing a point of reference for competing growth advantages and how median values change over time.
Further details on the model formats can be found in their respective citations.
All models were implemented using the evofr (evolutionary forecasting) software package in Python (https://pypi.org/project/evofr/) using Numpyro for inference.

We compare the four models to a naive model which is implemented as a 7-day moving average on the retrospective raw frequencies.

\paragraph{Evaluation Criteria}

We evaluate the error between the model predicted frequencies and the truth set averaged across each variant at a given time point using the mean absolute error (MAE).

\paragraph{Generating predictors of error}

We explored four key variables to describe the effect of sequencing efforts on nowcast errors and found their Spearman correlations with the nowcast errors.
These variables are defined as fraction of sequences available within 14 days of the prediction time, total sequences availability within 14 days of the prediction time, median delay of sequence submission, and lag time from prediction day subsequently for each location (Figure~\ref{fig:vars_of_interest}).
To calculate these variables, we selected a 14-day window of data before each and every observation date and used the collection and submission dates to determine their availability in addition to the period of discrepancy between the collection and submission for each country.
All variables were calculated using Rstudio statistical software \jhc{Cite RStudio.}.

%TODO: Add details on how we generate points for \ref{fig:vars_of_interest}


\paragraph{Downscaling historical sequencing effort}

We explored the effects of scaling back sequencing efforts to assess the effect of sequencing volume on nowcast and forecast errors.
Using sequences from the United Kingdom, we subsampled existing sequences at a rate of 100, 500, 1000, 1500, 2000, 2500, 3000, 3500, 4000, 4500, 5000 sequences per week at various \jhc{which?} observation dates throughout the pandemic.
We then fit the MLR forecast model to each resulting data set and forecast up to 30 days after observation date.
We then compared these forecasts to the truth set in previous sections to compute the forecast error for each model.

To better understand how the forecast error varies with sequencing intensity and forecast length, we computed the fraction of forecasts within a certain ``acceptable'' \jhc{maybe drop ``acceptable'' here, since the 5\% threshold is arbitrary.} error tolerance (5\% MAE) as well as the average error at difference sequence threshold and lag times.


\section*{Data and code accessibility}

Sequence data including date and location of collection as well as clade annotation was obtained via the Nextstrain-curated
dataset that pulls data from GISAID database \jhc{Create a GISAID DOI or acknowledgements table for all of the distinct sequences you used in this analysis. They provide a tool now to simplify the DOI creation.}.


Derived data of sequence counts and case counts, along with all source code used to analyze
this data and produce figures is available via the GitHub repository https://github.com/blab/ncov-forecasting-fit


%%% REFERENCES %%%
\bibliographystyle{plos}
\bibliography{ncov-forecasting-fit.bib}

\end{document}
